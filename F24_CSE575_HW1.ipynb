{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0201eef8",
   "metadata": {},
   "source": [
    "# Linear regression [7 pts]\n",
    "\n",
    "In this homework, you will implement solution algorithms for linear regression.\n",
    "\n",
    "\n",
    "## Import libraries\n",
    "Let's begin by importing some libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e93db53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7f958f",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "Now, we are importing a dataset of diabetes. You can check the details on this dataset here: https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset. \n",
    "\n",
    "The dataset consists of 442 observations with 10 attributes ($X$) that may affect the progression of diabetes ($y$). Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of $n$ = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45b7be6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the input features: (442, 10)\n",
      "The shape of the output varaible: (442,)\n"
     ]
    }
   ],
   "source": [
    "# Load the diabetes dataset\n",
    "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n",
    "print('The shape of the input features:',diabetes_X.shape)\n",
    "print('The shape of the output varaible:',diabetes_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d43652",
   "metadata": {},
   "source": [
    "We will choose just one attribute from the ten attributes as an input variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "333d01d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 1)\n"
     ]
    }
   ],
   "source": [
    "# Use only one feature\n",
    "diabetes_X_one = diabetes_X[:, np.newaxis, 2]\n",
    "print(diabetes_X_one.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5d51ee",
   "metadata": {},
   "source": [
    "## Dataset split\n",
    "\n",
    "Now, we split the dataset into two parts: training set and test set. \n",
    "\n",
    "- training set: 422 samples\n",
    "- test set: 20 samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b1cadcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input variable shape: (422, 1)\n",
      "Test input variable shape: (20, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X_one[:-20]\n",
    "diabetes_X_test = diabetes_X_one[-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = diabetes_y[:-20]\n",
    "diabetes_y_test = diabetes_y[-20:]\n",
    "\n",
    "print('Training input variable shape:', diabetes_X_train.shape)\n",
    "print('Test input variable shape:', diabetes_X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69db6e06",
   "metadata": {},
   "source": [
    "## Linear regression \n",
    "\n",
    "Assume that we have a hypothesis $$ h_{\\theta}(x) = \\theta_0 + \\theta_1 x. $$\n",
    "\n",
    "Your tasks: \n",
    "\n",
    "Implementation tasks:\n",
    "\n",
    "- [2pts] implement {your own version} of the method of least-squares, compute and report $\\theta_0$ and $\\theta_1$ that minimize the residual sum of squares, )\n",
    "$$ \\sum_{i=1}^{N} \\frac{1}{2}( y^{(i)} - h_{\\theta}(x^{(i)})^2$$\n",
    "\n",
    "[IMPORTANT] Do not just call the least square function from libraries, for example, \n",
    "scipy.optimize.least_squares from scipy. Doing so will result in 0 point. Using helping functions such as numpy.linalg.inv is okay. \n",
    "\n",
    "- [3pts] implement your own version of the gradient descent algorithm, compute and report $\\theta_0$ and $\\theta_1$ that minimize the mean squared error $$ \\sum_{i=1}^{N} \\frac{1}{N}( y^{(i)} - h_{\\theta}(x^{(i)})^2$$\n",
    "\n",
    "[NOTE] Notice that the loss function is mean-squared error. Implement the gradient descent update rule in a for loop.\n",
    "To check whether your computation is correct, consider using an API such as Scikit learn linearregression.\n",
    "\n",
    "\n",
    "- [2pts] derive the analytical expression of the gradient if the loss is defined as \n",
    "$$ \\sum_{i=1}^{N} \\frac{1}{2}( y^{(i)} - h_{\\theta}(x^{(i)})^2 + \\frac{\\lambda}{2} \\| \\theta \\|_2^2, $$\n",
    "where $\\theta = [\\theta_0, \\theta_1]^{\\intercal}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4784ff6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
